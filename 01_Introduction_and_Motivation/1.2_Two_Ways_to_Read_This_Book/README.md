# 1.2 Two Ways to Read This Book

## 두 가지 학습 전략
MML을 이해하기 위한 두 가지 전략
- **bottom-up** 방식 : 기초부터 고급 개념으로 단계적인 학습
  - 장점 : 이전에 배운 개념에 의존 가능
  - 단점 : 동기부여가 부족해 기초 개념을 빨리 잊을 수 있음
- **top-down** : 실용적인 필요에서 기초 개념으로 접근
  - 장점 : 왜 특정 개념을 공부하는지 명확히 이해
  - 단점 : 지식이 불안정한 기초 위에 구축될 수 있고, 이해하기 어려운 용어를 기억해야 함.

## 책의 구성
이 책은 수학적 개념을 응용과 분리하였으며, 두 부분으로 나눠져 있음.
- 1부 : 수학적 기초를 다룸
- 2부 : 1부의 개념을 기초로 한 주요 머신 러닝 문제들(회귀 분석, 차원 축소, 밀도 추정, 분류)을 다룸
  <img width="370" alt="스크린샷 2024-06-19 오후 1 01 41" src="https://github.com/star-books-coffee/MML/assets/101961939/917111b4-e95e-4b83-beab-457b227aef32">

## 복합적인 학습 접근
- 독자들은 하향식과 상향식을 결합하여 학습.
- 기본적인 수학적 기술을 쌓은 후 응용을 통해 더 복잡한 개념에 도전

## Part 1 - 수학에 관한 내용

### 선형대수학 (2장)
- 숫자 데이터를 벡터로, 데이터 표를 행렬료 표현
- 벡터와 행렬의 기본 개념을 다룬다.

### 해석기하학 (3장)
- 벡터 간의 유사성 측정을 위해 유사성과 거리 연산 도입

### 행렬 분해 (4장)
- 행렬의 기본 개념과 유용한 연산 소개
- 데이터 해석과 효율적인 학습을 위한 행렬 분해 기법

### 확률 이론 (6장) 
- 데이터의 노이즈(noise)와 신호(signal)을 구별하는 방법
- 예측 값에 대한 신뢰도 정량화

### 벡터 미적분학 및 최적화 (5장 & 7장)
- 벡터 미적분학에서 기울기(gradient) 개념을 다루고, 이를 기반으로 최적화 기법 설명
- 최적화는 머신 러닝 모델의 성능을 최대화하기 위한 파라미터 찾기

